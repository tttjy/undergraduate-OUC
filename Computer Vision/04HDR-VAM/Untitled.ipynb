{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5da9ae8",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SeparableConv2D' object has no attribute 'output_shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 192\u001b[0m\n\u001b[0;32m    190\u001b[0m     \u001b[38;5;28mprint\u001b[39m(profile)\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 192\u001b[0m     \u001b[43mtest_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 189\u001b[0m, in \u001b[0;36mtest_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodel_profiler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m model_profiler\n\u001b[0;32m    188\u001b[0m model_ \u001b[38;5;241m=\u001b[39m model()\n\u001b[1;32m--> 189\u001b[0m profile \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_profiler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28mprint\u001b[39m(profile)\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\pytorch\\Lib\\site-packages\\model_profiler\\profiler.py:63\u001b[0m, in \u001b[0;36mmodel_profiler\u001b[1;34m(model, Batch_size, profile, use_units, verbose)\u001b[0m\n\u001b[0;32m     61\u001b[0m     mem_req \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m mem_for_storing_weights(use_units[\u001b[38;5;241m4\u001b[39m], model\u001b[38;5;241m.\u001b[39mlayers[func_idx\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m:])\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 63\u001b[0m     flops \u001b[38;5;241m=\u001b[39m \u001b[43mcount_flops\u001b[49m\u001b[43m(\u001b[49m\u001b[43muse_units\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     64\u001b[0m     mem \u001b[38;5;241m=\u001b[39m keras_model_memory_usage(use_units[\u001b[38;5;241m2\u001b[39m], model, Batch_size)\n\u001b[0;32m     65\u001b[0m     param \u001b[38;5;241m=\u001b[39m get_param(use_units[\u001b[38;5;241m3\u001b[39m], model)\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\pytorch\\Lib\\site-packages\\model_profiler\\utils.py:24\u001b[0m, in \u001b[0;36mmultiply.<locals>.deco\u001b[1;34m(units, *args, **kwds)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(units, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m---> 24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mround(multiplier\u001b[38;5;241m.\u001b[39mget(units, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m4\u001b[39m)\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\pytorch\\Lib\\site-packages\\model_profiler\\utils.py:208\u001b[0m, in \u001b[0;36mcount_flops\u001b[1;34m(model, log)\u001b[0m\n\u001b[0;32m    206\u001b[0m     layer_flops\u001b[38;5;241m.\u001b[39mappend(count_linear(layer))\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconv\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m layer\u001b[38;5;241m.\u001b[39mget_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m--> 208\u001b[0m     layer_flops\u001b[38;5;241m.\u001b[39mappend(\u001b[43mcount_conv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlog\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdwconv\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m layer\u001b[38;5;241m.\u001b[39mget_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    210\u001b[0m     layer_flops\u001b[38;5;241m.\u001b[39mappend(count_conv2d(layer,log))\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\pytorch\\Lib\\site-packages\\model_profiler\\utils.py:153\u001b[0m, in \u001b[0;36mcount_conv2d\u001b[1;34m(layers, log)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcount_conv2d\u001b[39m(layers, log \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    150\u001b[0m     \u001b[38;5;66;03m# if log:\u001b[39;00m\n\u001b[0;32m    151\u001b[0m     \u001b[38;5;66;03m#     print(layers.get_config())\u001b[39;00m\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;66;03m# number of conv operations = input_h * input_w / stride = output^2\u001b[39;00m\n\u001b[1;32m--> 153\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_shape\u001b[49m[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    154\u001b[0m         numshifts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(layers\u001b[38;5;241m.\u001b[39moutput_shape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m layers\u001b[38;5;241m.\u001b[39moutput_shape[\u001b[38;5;241m2\u001b[39m])\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m layers\u001b[38;5;241m.\u001b[39moutput_shape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'SeparableConv2D' object has no attribute 'output_shape'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def feature_extractor(input_img):\n",
    "  features = tf.keras.layers.SeparableConv2D(32,3,padding='same')(input_img)\n",
    "  features_max = tf.keras.layers.MaxPool2D(2)(features)\n",
    "  features_avg = tf.keras.layers.AvgPool2D(2)(features)\n",
    "  \n",
    "  concat = tf.keras.layers.concatenate([features_max,features_avg])\n",
    "  features = tf.keras.layers.SeparableConv2D(32,3,activation = 'relu',padding='same')(concat)\n",
    "  features = tf.keras.layers.UpSampling2D(2)(features)\n",
    "  \n",
    "  return features\n",
    "  \n",
    "def alingment(input_i,input_r):\n",
    "  input_reference = tf.keras.layers.Conv2D(32,3,padding='same',activation='relu')(input_r)\n",
    "  input_reference1 = tf.keras.layers.Conv2D(32,3,padding='same',activation='relu')(input_reference)\n",
    "  input_reference2 = tf.keras.layers.Conv2D(32,3,padding='same',activation='relu')(input_reference)\n",
    "  \n",
    "  multiplication = tf.keras.layers.multiply([input_i,input_reference1])\n",
    "  out = tf.keras.layers.add([multiplication,input_reference2])\n",
    "  \n",
    "  return out\n",
    "  \n",
    "def attention(input_i,input_r):\n",
    "  concat = tf.keras.layers.concatenate([input_i,input_r],axis=-1)\n",
    "  x = tf.keras.layers.SeparableConv2D(64,3,padding='same',activation='relu')(concat)\n",
    "  sigmoid = tf.keras.layers.SeparableConv2D(32,3,padding='same',activation='sigmoid')(x)\n",
    "  return sigmoid\n",
    "\n",
    "def alignment_attention(input_i,input_r_alingment,input_r_attention):\n",
    "  \n",
    "  input_i_alignment = feature_extractor(input_i[:,:,:,0:3])\n",
    "  input_i_attention = feature_extractor(input_i[:,:,:,3:])\n",
    "  \n",
    "  align_i = alingment(input_i_alignment,input_r_alingment)\n",
    "  attention_i = attention(input_i_attention,input_r_attention)\n",
    "  \n",
    "\n",
    "  return(align_i,attention_i)\n",
    "  \n",
    "def visual_attention(inps,masks):\n",
    "  low_multiplication = tf.keras.layers.multiply([inps[0],masks[0]] ,name ='low_multiplication')\n",
    "  high_multiplication = tf.keras.layers.multiply([inps[1],masks[1]] ,name ='high_multiplication')\n",
    "  \n",
    "  low_features = feature_extractor(low_multiplication)\n",
    "  high_features = feature_extractor(high_multiplication)\n",
    "  \n",
    "  \n",
    "  addition = tf.keras.layers.add([low_features,high_features])\n",
    "  \n",
    "  return addition\n",
    "   \n",
    "def reconstruction(inps,addition):\n",
    "    reference = inps[:,:,:,-64:]\n",
    "    x = tf.keras.layers.SeparableConv2D(64,(3,3), padding = 'same')(inps) #(256,256)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    avg_pool = tf.keras.layers.AveragePooling2D((2,2))(x) #(128,128)\n",
    "    max_pool = tf.keras.layers.MaxPool2D((2,2))(x)        #(128,128)\n",
    "    concat = tf.keras.layers.concatenate([avg_pool,max_pool])\n",
    "\n",
    "    x = tf.keras.layers.SeparableConv2D(128,(3,3), padding = 'same')(concat)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    avg_pool = tf.keras.layers.AveragePooling2D((2,2))(x) #(64,64)\n",
    "    max_pool = tf.keras.layers.MaxPool2D((2,2))(x)        #(64,64)\n",
    "    concat = tf.keras.layers.concatenate([avg_pool,max_pool])\n",
    "    \n",
    "\n",
    "    x = tf.keras.layers.SeparableConv2D(256,(3,3), padding = 'same')(concat)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    avg_pool = tf.keras.layers.AveragePooling2D((2,2))(x) #(32,32)\n",
    "    max_pool = tf.keras.layers.MaxPool2D((2,2))(x)        #(32,32)\n",
    "    concat = tf.keras.layers.concatenate([avg_pool,max_pool])\n",
    "    \n",
    "    \n",
    "    x = tf.keras.layers.SeparableConv2D(256,(3,3), padding = 'same')(concat)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    avg_pool = tf.keras.layers.AveragePooling2D((2,2))(x) #(16,16)\n",
    "    max_pool = tf.keras.layers.MaxPool2D((2,2))(x)        #(16,16)\n",
    "    concat = tf.keras.layers.concatenate([avg_pool,max_pool])\n",
    "    \n",
    "    \n",
    "    # Making the ref image and add layer the same size of (16,16).\n",
    "    add_avg_pool = tf.keras.layers.AveragePooling2D((16,16))(addition)\n",
    "    \n",
    "    med_avg_pool = tf.keras.layers.AveragePooling2D((16,16))(reference)\n",
    "    \n",
    "    cat = tf.keras.layers.concatenate([concat,add_avg_pool,med_avg_pool])\n",
    "    x = tf.keras.layers.SeparableConv2D(256,(3,3), padding = 'same', activation = 'relu')(cat)\n",
    "    x = tf.keras.layers.UpSampling2D((2,2))(x) #(32,32)\n",
    "    \n",
    "    # Making the ref image and add layer the same size of (32,32).\n",
    "    add_avg_pool = tf.keras.layers.AveragePooling2D((8,8))(addition)\n",
    "    \n",
    "    med_avg_pool = tf.keras.layers.AveragePooling2D((8,8))(reference)\n",
    "    \n",
    "    cat = tf.keras.layers.concatenate([x,add_avg_pool,med_avg_pool])\n",
    "    x = tf.keras.layers.SeparableConv2D(128,(3,3), padding = 'same', activation = 'relu')(cat)\n",
    "    x = tf.keras.layers.UpSampling2D((2,2))(x) #(64,64)\n",
    "\n",
    "    # Making the ref image and add layer the same size of (64,64).\n",
    "    add_avg_pool = tf.keras.layers.AveragePooling2D((4,4))(addition)\n",
    "    \n",
    "    med_avg_pool = tf.keras.layers.AveragePooling2D((4,4))(reference)\n",
    "    \n",
    "    cat = tf.keras.layers.concatenate([x,add_avg_pool,med_avg_pool])\n",
    "    x = tf.keras.layers.SeparableConv2D(64,(3,3), padding = 'same', activation = 'relu')(cat)\n",
    "    x = tf.keras.layers.UpSampling2D((2,2))(x) #(128,128)\n",
    "\n",
    "    # Making the ref image and add layer the same size of (128,128).\n",
    "    add_avg_pool = tf.keras.layers.AveragePooling2D((2,2))(addition)\n",
    "    \n",
    "    med_avg_pool = tf.keras.layers.AveragePooling2D((2,2))(reference)\n",
    "    \n",
    "    cat = tf.keras.layers.concatenate([x,add_avg_pool,med_avg_pool])\n",
    "    x = tf.keras.layers.SeparableConv2D(32,(3,3), padding = 'same', activation = 'relu')(cat)\n",
    "    x = tf.keras.layers.UpSampling2D((2,2))(x) #(256,256)\n",
    "\n",
    "    out = tf.keras.layers.SeparableConv2D(3,(1,1), padding='same',activation='relu')(x)\n",
    "    return (out)\n",
    "\n",
    "def refinement(input,reconstructed):\n",
    "    input = tf.keras.layers.SeparableConv2D(3,3,padding='same',activation='relu')(input)\n",
    "    \n",
    "    concat = tf.keras.layers.concatenate([reconstructed,input])\n",
    "    x = tf.keras.layers.SeparableConv2D(16,(3,3),padding='same')(concat)\n",
    "    x = tf.keras.layers.SeparableConv2D(16,(3,3),padding='same',activation='relu')(x)\n",
    "\n",
    "    concat = tf.keras.layers.concatenate([x,input])\n",
    "    x = tf.keras.layers.SeparableConv2D(16,(3,3),padding='same')(concat)\n",
    "    x = tf.keras.layers.SeparableConv2D(16,(3,3),padding='same',activation='relu')(x)\n",
    "\n",
    "    concat = tf.keras.layers.concatenate([x,input])\n",
    "    x = tf.keras.layers.SeparableConv2D(16,(3,3),padding='same')(concat)\n",
    "    x = tf.keras.layers.SeparableConv2D(16,(3,3),padding='same',activation='relu')(x)\n",
    "\n",
    "    final = tf.keras.layers.Conv2D(3,(1,1),padding='same',activation='sigmoid',name='Final_output')(x)\n",
    "\n",
    "    return final\n",
    "\n",
    "def visual_mask_expansion(mask):\n",
    "    \n",
    "    #This function expands the number of channels of the masks into 6.\n",
    "    \n",
    "    exp_mask = tf.keras.layers.concatenate([mask,mask],axis=-1)\n",
    "    exp_mask = tf.keras.layers.concatenate([exp_mask,mask],axis=-1)\n",
    "    return exp_mask\n",
    "\n",
    "def model():\n",
    "    low_input = tf.keras.layers.Input((None,None) + (6,),name='input_low')\n",
    "    medium_input = tf.keras.layers.Input((None,None) + (6,),name='input_medium')\n",
    "    high_input = tf.keras.layers.Input((None,None) + (6,),name='input_high')\n",
    "    low_mask = tf.keras.layers.Input((None,None) + (2,),name='input_low_mask')\n",
    "    high_mask = tf.keras.layers.Input((None,None) + (2,),name='input_high_mask')\n",
    "    \n",
    "    #expand visual segmentations to 6 channels\n",
    "    exp_low_mask = visual_mask_expansion(low_mask)\n",
    "    exp_high_mask = visual_mask_expansion(high_mask)\n",
    "    \n",
    "    # visual alignment\n",
    "    add = visual_attention([low_input,high_input],[exp_low_mask,exp_high_mask])\n",
    "    \n",
    "    reference_features_alignment = feature_extractor(medium_input)\n",
    "    reference_features_attention = feature_extractor(medium_input)\n",
    "    reference_features = tf.keras.layers.concatenate([reference_features_alignment,reference_features_attention],axis=-1)\n",
    "    \n",
    "    #image alignment and attention\n",
    "    align_low,attention_low = alignment_attention(low_input,reference_features_alignment,reference_features_attention)\n",
    "    align_high, attention_high = alignment_attention(high_input,reference_features_alignment,reference_features_attention) \n",
    "\n",
    "    inps = tf.keras.layers.concatenate([align_low,attention_low,align_high,attention_high,add,reference_features],axis=-1)\n",
    "\n",
    "    #reconstruction stage\n",
    "    reconstructed = reconstruction(inps,add)\n",
    "\n",
    "    #refinement stage\n",
    "    final_out = refinement(reference_features,reconstructed)\n",
    "\n",
    "    model = tf.keras.Model(inputs=[low_input,medium_input,high_input,low_mask,high_mask],outputs=final_out)\n",
    "    return(model)\n",
    "model()\n",
    "\n",
    "def test_model():\n",
    "    from model_profiler import model_profiler\n",
    "    model_ = model()\n",
    "    profile = model_profiler(model_,1)\n",
    "    print(profile)\n",
    "if __name__ == '__main__':\n",
    "    test_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2390dd05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
